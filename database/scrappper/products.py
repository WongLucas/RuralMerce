import requests
from bs4 import BeautifulSoup
import json

# URL da Wiki oficial (Fandom)
url = "https://bindingofisaacrebirth.fandom.com/wiki/Items"

try:
    print("üåç Conectando ao Wiki de Isaac...")
    response = requests.get(url)
    response.raise_for_status()
except requests.exceptions.RequestException as e:
    print(f"‚ùå Erro ao conectar: {e}")
    exit()

soup = BeautifulSoup(response.content, "html.parser")

# Busca todas as tabelas com a classe 'wikitable'
tables = soup.find_all("table", class_="wikitable")

if not tables:
    print("‚ùå Nenhuma tabela encontrada!")
    exit()

print(f"‚úÖ {len(tables)} tabelas encontradas. Processando as principais...\n")

all_items = []

# Loop pelas tabelas encontradas
for index, table in enumerate(tables):

    # L√≥gica para identificar o tipo baseado na ordem da p√°gina
    # 0 = Active Items, 1 = Passive Items
    if index == 0:
        item_type = "Active"
    elif index == 1:
        item_type = "Passive"
    else:
        # Se quiser parar ap√≥s as duas primeiras, descomente a linha abaixo:
        break
        # item_type = "Other" # Caso queira pegar trinkets ou outras tabelas depois

    print(f"üîÑ Processando tabela {index + 1}: {item_type} Items...")

    rows = table.find_all("tr")

    if not rows:
        continue

    # Pega os cabe√ßalhos (Ex: Name, Icon, Description...)
    headers = [th.get_text(strip=True) for th in rows[0].find_all(["th", "td"])]

    # Tratamento caso haja colunas sem nome
    headers = [h if h else f"Col_{i}" for i, h in enumerate(headers)]

    # Itera sobre as linhas de dados (pulando o cabe√ßalho)
    for row in rows[1:]:
        cols = row.find_all(["td", "th"])
        col_data = []

        # Itera sobre cada c√©lula da linha
        for col_idx, col in enumerate(cols):

            # Pega o nome do header correspondente para saber se √© a coluna de √≠cone
            # (Seguran√ßa: verifica se o √≠ndice existe em headers)
            current_header = headers[col_idx] if col_idx < len(headers) else ""

            # --- AQUI EST√Å A DICA DE OURO ---
            # Se a coluna for "Icon", extra√≠mos a URL da imagem em vez do texto
            if "Icon" in current_header:
                img_tag = col.find("img")
                if img_tag:
                    # O Fandom costuma usar 'data-src' para lazy loading. Se n√£o tiver, pega 'src'.
                    raw_url = img_tag.get("data-src") or img_tag.get("src")

                    if raw_url:
                        # Limpeza da URL: Remove tudo depois de "/revision" para pegar a imagem original
                        # Ex: imagem.png/revision/latest/scale-to-width... -> imagem.png
                        clean_url = raw_url.split("/revision")[0]
                        col_data.append(clean_url)
                    else:
                        col_data.append(None)
                else:
                    col_data.append(None)

            # Se n√£o for √≠cone, pega o texto normal
            else:
                text = col.get_text(" ", strip=True)
                col_data.append(text)

        # Monta o objeto se o n√∫mero de colunas bater
        # (As vezes as tabelas t√™m c√©lulas mescladas, ignoramos linhas quebradas por seguran√ßa)
        if len(col_data) == len(headers):
            item = dict(zip(headers, col_data))

            # Adiciona campos extras √∫teis para o seu sistema
            item['type'] = item_type # Active ou Passive

            # Renomeia a chave do √≠cone para algo mais amig√°vel pro banco de dados (opcional)
            if "Icon" in item:
                item['image_url'] = item.pop("Icon")

            all_items.append(item)

# Salva em JSON
output_file = "isaac_items_full.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(all_items, f, ensure_ascii=False, indent=2)

print(f"\nüöÄ Sucesso! {len(all_items)} itens extra√≠dos.")
print(f"üíæ Dados salvos em '{output_file}'. Agora √© s√≥ criar o seed no Adonis!")
